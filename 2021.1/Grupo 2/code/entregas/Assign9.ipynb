{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assign9.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renanalencar/projeto-md-emocoes/blob/main/entregas/Assign9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wps6DfhCJLiW"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pOn8CDHEtl1"
      },
      "source": [
        "# 1. Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvx59ETwExt9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imjqTSPSE0N8"
      },
      "source": [
        "# importar os pacotes necessários\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqzHS6G1E5Ii"
      },
      "source": [
        "arquivo_tedio = \"/content/drive/Shareddrives/MINERAÇÃO DE DADOS ENG74291/Assign6/dadosTedioProcessados.xlsx\"\n",
        "df_tedio = pd.read_excel(arquivo_tedio, index_col=0)\n",
        "\n",
        "# CSV apenas com as emoções. Pontos euclidianos foram removidos\n",
        "# deixar no dataframe somente com as linhas correspondentes ao game_id 1\n",
        "df_tedio = df_tedio.drop(df_tedio.iloc[:, 9:35], axis=1)\n",
        "filtro  = df_tedio[\"game_id\"] == 1\n",
        "df_tedio = df_tedio[filtro]\n",
        "\n",
        "# remove a coluna game_name\n",
        "#del df_tedio[\"game_name\"]\n",
        "\n",
        "# visualizar as 8 primeiras entradas do df\n",
        "df_tedio.head(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PgrEKH1E9DD"
      },
      "source": [
        "# verificar o tamanho do df\n",
        "print(\"Variáveis:\\t {}\".format(df_tedio.shape[1]))\n",
        "print(\"Entradas:\\t {}\".format(df_tedio.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a67XjVOE_Qr"
      },
      "source": [
        "# vizualisar os nomes das colunas\n",
        "df_tedio.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deRAC6RfFBJU"
      },
      "source": [
        "# descobrir os tipos das variáveis\n",
        "df_tedio.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UjhHXvXFGf0"
      },
      "source": [
        "## 1.2 Criando classes para a base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X1hKMjtFHU1"
      },
      "source": [
        "# função para classificar os dados como tédio (1) ou estresse (0)\n",
        "def def_tedio(c):\n",
        "  if c['angry'] >= 0.1 and c['disgusted'] >= 0.1:\n",
        "    return 1\n",
        "  elif c['sad'] >= 0.1 and c['surprised'] >= 0.1:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WySuYpemFKJ7"
      },
      "source": [
        "# criar a coluna 'target' para o df_tedio\n",
        "df_tratado = pd.DataFrame(df_tedio)\n",
        "\n",
        "df_tratado['target'] = df_tedio.apply(def_tedio, axis=1)\n",
        "\n",
        "df_tratado.head(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEOPbVPoFOFE"
      },
      "source": [
        "# verificar o tipo de dado de cada coluna\n",
        "df_tratado.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YiHbL6uFRgR"
      },
      "source": [
        "# verificar que colunas tem valores NaN (Not a Number)\n",
        "df_tratado.isnull().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvZK6hcDbLVb"
      },
      "source": [
        "# Completando os registros que tem valor NaN com 0.0\n",
        "df_tratado = df_tratado.fillna(0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wmEViSFFYNp"
      },
      "source": [
        "## 1.3 Conjunto de dados para treinamento e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQwuUp-gFdmC"
      },
      "source": [
        "# criar os conjuntos de dados e classes para treinamento e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(df_tratado.drop(columns=['target']), df_tratado.target, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GPD14CRFhNb"
      },
      "source": [
        "## 1.4 Correlação\n",
        "Baseado em [Como selecionar as melhores features para seu modelo de Machine Learning](https://paulovasconcellos.com.br/como-selecionar-as-melhores-features-para-seu-modelo-de-machine-learning-2e9df83d062a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wblj-4QlFlb9"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(df_tratado.corr(),\n",
        "            annot = True,\n",
        "            fmt = '.2f',\n",
        "            cmap='Blues')\n",
        "plt.title('Correlação entre variáveis do dataset de tédio')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCeDkz9mGLv-"
      },
      "source": [
        "O valor mostrado para cada correlação vai de -1 — que indica uma correlação negativa perfeita — a +1 — uma correlação positiva perfeita. Vale lembrar que a função .corr() traz, por padrão, a correlação de Pearson, mostrando um relacionamento linear entre as variáveis. Em casos onde há um relacionamento não-linear, a matriz pode não ser uma boa medida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQLvtOuYGOgw"
      },
      "source": [
        "## 1.5 Feature Importance\n",
        "O feature_importance_ retornar um array onde cada elemento dele é uma feature do seu modelo. Ele irá dizer, em proporções, quão importante aquela feature é para o modelo, onde quanto maior o valor, mais importante a feature é para o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FziStAjzGRRe"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf_RFC  = RandomForestClassifier()\n",
        "clf_RFC.fit(X_treinamento, y_treinamento)\n",
        "\n",
        "# Mostrando importância de cada feature\n",
        "clf_RFC.feature_importances_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjOFxalYGUxc"
      },
      "source": [
        "É retornado um array com quatro elementos. Se você somar todos eles, verá que o resultado será 1. Ao analisar esse array, podemos ver que a feature mais importante para o algoritmo Floresta Randômica foi a variável 'surprised'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GDFAXthGYAN"
      },
      "source": [
        "importances = pd.Series(data=clf_RFC.feature_importances_, index=df_tratado.columns[0:9])\n",
        "sns.barplot(x=importances, y=importances.index, orient='h').set_title('Importância de cada feature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doxegZRCGbg-"
      },
      "source": [
        "As vezes, os valores mostrados pelo feature_importances_ pode ser enviesado dependendo dos parâmetros definidos na criação do objeto. Evitar usar os parâmetros default do Floresta Randômica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOde8tskHpqs"
      },
      "source": [
        "# 2. Regressões"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqITYIOVGpYv"
      },
      "source": [
        "## 2.1 Regressão Linear Simples e Multipla\n",
        "\n",
        "\n",
        "*   [Linear Regression Example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html)\n",
        "*   [Implementando Regressão Linear Simples em Python](https://medium.com/data-hackers/implementando-regress%C3%A3o-linear-simples-em-python-91df53b920a8)\n",
        "*   [Regressão Linear](https://www.kaggle.com/marilivb/4-regress-o-linear)\n",
        "*   [https://www.datageeks.com.br/regressao-linear/](https://www.datageeks.com.br/regressao-linear/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn4Qc8-XGwZ6"
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO8xmDLZGz3u"
      },
      "source": [
        "# Criar um objeto de regressão linear\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Treinar o modelo usando os conjuntos de treinamento\n",
        "regr.fit(X_treinamento, y_treinamento)\n",
        "\n",
        "# Fazer predições usando o conjunto de teste\n",
        "y_pred = regr.predict(X_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exvw2aRYG2UC"
      },
      "source": [
        "# Os coeficientes encontrados\n",
        "print('Coeficientes: \\n', regr.coef_)\n",
        "# O Erro Médio Quadrático (EMQ)\n",
        "print('Erro Médio Quadrático (EMQ): %.2f'\n",
        "      % mean_squared_error(y_teste, y_pred))\n",
        "# O coeficiente de determinação: 1 é a predição perfeita\n",
        "print('Coeficiente de determinação: %.2f'\n",
        "      % r2_score(y_teste, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK1eG-s3G5xm"
      },
      "source": [
        "### 2.1.1 Diagrama de Dispersão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM-WBfwnG7e0"
      },
      "source": [
        "# plotar saídas\n",
        "plt.scatter(X_teste.iloc[:,0].values, y_teste,  color='black')\n",
        "plt.plot(X_teste, y_pred, color='blue', linewidth=3)\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV10sdS7HAxW"
      },
      "source": [
        "## 2.2 Regressão Logística\n",
        "\n",
        "\n",
        "*   [Logistic Regression using Python (scikit-learn)](https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a)\n",
        "*   [Regressão Logística e Métricas de Classificação em Python](http://neylsoncrepalde.github.io/2019-11-25-regressao_logistica_python/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOakVAdEG_Sy"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf_LR = LogisticRegression(random_state=0).fit(X_treinamento, y_treinamento)\n",
        "clf_LR.predict(X_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKSvVatgHFbN"
      },
      "source": [
        "clf_LR.predict_proba(X_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naZMLGCAHG3q"
      },
      "source": [
        "clf_LR.score(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mOUK41FHM9G"
      },
      "source": [
        "### 2.2.1 Diagrama de Dispersão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuLRWhciHJlv"
      },
      "source": [
        "# plotar saídas\n",
        "plt.scatter(X_teste.iloc[:,0].values, y_teste,  color='black')\n",
        "plt.plot(X_teste, y_pred, color='blue', linewidth=3)\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj4iZ82YJiyH"
      },
      "source": [
        "# 3. Detecção de anomalias\n",
        "Referências:\n",
        "\n",
        "\n",
        "*   [Anomaly Detection Techniques in Python](https://medium.com/learningdatascience/anomaly-detection-techniques-in-python-50f650c75aaf)\n",
        "*   [4 Automatic Outlier Detection Algorithms in Python](https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/)\n",
        "*   [Learn how to develop highly accurate models to detect anomalies using Artificial Neural Networks with the Tensorflow library in Python3.](https://outline.com/D8jZMf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50muSTiipaKj"
      },
      "source": [
        "## 3.1 Métodos Estatísticos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnm44wf_pdkD"
      },
      "source": [
        "### 3.1.1 Paramétricos: Diagrama de Caixa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8axwjIOCdoJC"
      },
      "source": [
        "boxplot = df_tratado.boxplot(column=['angry', 'disgusted', 'fear', 'sad', 'surprised', 'happy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I458mNlWuG-K"
      },
      "source": [
        "df_emocoes = df_tratado.copy(deep=True)\n",
        "df_emocoes = df_emocoes.drop(columns=['game_id', 'uuid', 'timestamp', 'target'])\n",
        "ax = sns.violinplot(data=df_emocoes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2QSTDoapiDA"
      },
      "source": [
        "### 3.1.2 Não Paramétricos: Análise de Histograma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX_o3sSVi8zk"
      },
      "source": [
        "#ax = df_emocoes.plot.hist(bins=12, alpha=0.5)\n",
        "ax = df_emocoes.plot.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LYrjzY5plQs"
      },
      "source": [
        "## 3.2 Métodos Algorítmicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D42mzAjkpqjt"
      },
      "source": [
        "### 3.2.1 Proximidade: Local Outlier Factor (LOF)\n",
        "Referências:\n",
        "\n",
        "*   [2.7. Novelty and Outlier Detection](https://scikit-learn.org/stable/modules/outlier_detection.html)\n",
        "*   [sklearn.neighbors.LocalOutlierFactor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html)\n",
        "*   [Outlier detection with Local Outlier Factor (LOF)](https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html)\n",
        "*   [Anomaly detection with Local Outlier Factor (LOF)](https://towardsdatascience.com/anomaly-detection-with-local-outlier-factor-lof-d91e41df10f2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvyBtHbK6t3Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsguuBIQpt_F"
      },
      "source": [
        "### 3.2.2 Redes Neurais: Redes Neurais Supervisionadas\n",
        "Referências:\n",
        "\n",
        "\n",
        "*   [Comparing anomaly detection algorithms for outlier detection on toy datasets](https://scikit-learn.org/0.20/auto_examples/plot_anomaly_comparison.html)\n",
        "*   [How to use machine learning for anomaly detection and condition monitoring](https://towardsdatascience.com/how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring-6742f82900d7)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_HWU1AKpwux"
      },
      "source": [
        "## 3.3 Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FLYQE11qJ-m"
      },
      "source": [
        "### 3.3.1. Árvores de decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn3DEFYiqNm7"
      },
      "source": [
        "### 3.3.2 Florestas de isolamento (*Isolation Forest*)\n",
        "Referências:\n",
        "\n",
        "*   [2.7. Novelty and Outlier Detection](https://scikit-learn.org/stable/modules/outlier_detection.html)\n",
        "*   [sklearn.ensemble.IsolationForest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html)\n",
        "*   [Anomaly Detection with Isolation Forest & Visualization](https://towardsdatascience.com/anomaly-detection-with-isolation-forest-visualization-23cd75c281e2)\n",
        "*   [Anomaly Detection Using Isolation Forest in Python](https://blog.paperspace.com/anomaly-detection-isolation-forest/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q38oExSG6-II"
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "model=IsolationForest(n_estimators=50, max_samples='auto', contamination=float(0.1),max_features=1.0)\n",
        "model.fit(df_emocoes[['angry']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-wU8DRt7isD"
      },
      "source": [
        "df = pd.DataFrame(df_emocoes['angry'])\n",
        "df['scores']=model.decision_function(df[['angry']])\n",
        "df['anomaly']=model.predict(df[['angry']])\n",
        "df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqH1L6gs8EGv"
      },
      "source": [
        "anomaly=df.loc[df['anomaly']==-1]\n",
        "anomaly_index=list(anomaly.index)\n",
        "print(anomaly)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijIrQgZw8sLx"
      },
      "source": [
        "outliers_counter = len(df[df['angry'] > 0.5])\n",
        "outliers_counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xN4NinX81s-"
      },
      "source": [
        "print(\"Accuracy percentage:\", 100*list(df['anomaly']).count(-1)/(outliers_counter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoobMdZs9UPn"
      },
      "source": [
        "#specify the 12 metrics column names to be modelled\n",
        "to_model_columns=df_emocoes[0:7]\n",
        "to_model_columns\n",
        "\n",
        "clf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.12), max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
        "clf.fit(df_emocoes)\n",
        "pred = clf.predict(df_emocoes)\n",
        "df_emocoes['anomaly']=pred\n",
        "outliers=df_emocoes.loc[df_emocoes['anomaly']==-1]\n",
        "outlier_index=list(outliers.index)\n",
        "print(outlier_index)\n",
        "#Find the number of anomalies and normal points here points classified -1 are anomalous\n",
        "print(df_emocoes['anomaly'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_26CGxe_g9P"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(2)\n",
        "pca.fit(df_emocoes)\n",
        "res=pd.DataFrame(pca.transform(df_emocoes))\n",
        "Z = np.array(res)\n",
        "plt.title(\"IsolationForest\")\n",
        "plt.contourf( Z, cmap=plt.cm.Blues_r)\n",
        "b1 = plt.scatter(res[0], res[1], c='green', s=20,label=\"normal points\")\n",
        "b1 =plt.scatter(res.iloc[outlier_index,0],res.iloc[outlier_index,1], c='green',s=20,  edgecolor=\"red\",label=\"predicted outliers\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9nOn40EArDG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "pca = PCA(n_components=3)  # Reduce to k=3 dimensions\n",
        "scaler = StandardScaler()\n",
        "#normalize the metrics\n",
        "X = scaler.fit_transform(df_emocoes)\n",
        "X_reduce = pca.fit_transform(X)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_zlabel(\"x_composite_3\")# Plot the compressed data points\n",
        "ax.scatter(X_reduce[:, 0], X_reduce[:, 1], zs=X_reduce[:, 2], s=4, lw=1, label=\"inliers\",c=\"green\")# Plot x's for the ground truth outliers\n",
        "ax.scatter(X_reduce[outlier_index,0],X_reduce[outlier_index,1], X_reduce[outlier_index,2],\n",
        "           lw=2, s=60, marker=\"x\", c=\"red\", label=\"outliers\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}